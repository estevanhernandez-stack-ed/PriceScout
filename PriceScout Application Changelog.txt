  PriceScout Application Changelog

  This document outlines the major changes, new features, and improvements that have been implemented in the
   PriceScout application, transitioning it from a single monolithic file to a robust, modular application.

  ‚ú® New Features

   * Modular Architecture: The application has been completely refactored from a single script into a modular
     structure. We now have dedicated modules for the user interface (price_scout_app.py), data scraping
     (scraper.py), database interactions (database.py), UI components (ui_components.py), and configuration
     (config.py).
   * Data Management Mode: A new workflow has been added to clean, match, and prepare theater data, ensuring
     higher data quality before a scrape is run.
   * Historical Analysis Mode: A powerful "Analysis Mode" has been introduced. This allows for deep dives into
      historical pricing data with advanced filtering and trend reporting.
   * Database Integration: The application now uses a SQLite database to store all historical scrape data,
     enabling persistent storage and more complex data analysis.
   * Task Scheduler: You can now schedule automated scraping tasks through the UI, defining the markets, time,
      and notification preferences.
   * Developer Mode: A special mode has been added to provide debugging tools, including the ability to
     capture HTML snapshots of scraped pages.
   * Select/Deselect All Films: For a better user experience, "Select All" and "Deselect All" buttons have
     been added to the film selection step in both Market and CompSnipe modes.
   * Load Latest Markets File: The Data Management mode now includes a "Load Latest" button, which
     automatically finds and loads the most recently modified markets.json file, streamlining the workflow.

  üîß Refactoring & Code Quality

   * Improved UI/UX: The user interface has been significantly overhauled. It now features a more organized
     layout, a persistent sidebar for navigation, and makes better use of Streamlit components for a cleaner
     experience.
   * Asynchronous Scraping: All scraping processes now run in a separate thread. This keeps the UI responsive
     and prevents the application from freezing during long-running tasks.
   * Unified Scraper: The two separate scraper files (scraper.py and scraper_v2.py) have been consolidated
     into a single, more robust scraper module. This ensures consistency and simplifies future maintenance.
   * Centralized Configuration: Application settings have been moved to a central config.py file, making it
     easier to manage and modify configurations.
   * Code Readability: By breaking the code into smaller, more focused functions and modules, the overall
     readability and maintainability of the project have been greatly improved.

  üêû Bug Fixes & Performance

   * Application Crash on Search: Resolved a critical ValueError that caused the application to crash when a
     search was initiated.
   * Silent Zipcode Search Failure: Fixed a bug in "CompSnipe Mode" where a failed zipcode search would not
     provide any error message to the user.
   * Improved Error Handling: Error reporting is now more specific. Instead of generic failure messages, the
     application provides more detailed information about the cause of the error.
   * Asynchronous Function Call Correction: Fixed several incorrect calls to asynchronous functions that could
      have led to unexpected behavior or crashes.
   * Updated Dependencies: The requirements.txt file has been cleaned up to remove unused libraries and
     accurately reflect the project's current dependencies.